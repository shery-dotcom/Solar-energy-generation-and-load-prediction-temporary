{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d8d5c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm==3.3.2\n",
      "  Downloading lightgbm-3.3.2-py3-none-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: wheel in c:\\users\\pc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from lightgbm==3.3.2) (0.45.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\pc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from lightgbm==3.3.2) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\pc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from lightgbm==3.3.2) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in c:\\users\\pc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from lightgbm==3.3.2) (1.6.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\pc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm==3.3.2) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\pc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm==3.3.2) (3.5.0)\n",
      "Downloading lightgbm-3.3.2-py3-none-win_amd64.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 0.5/1.0 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.0/1.0 MB 4.0 MB/s eta 0:00:00\n",
      "Installing collected packages: lightgbm\n",
      "  Attempting uninstall: lightgbm\n",
      "    Found existing installation: lightgbm 4.6.0\n",
      "    Uninstalling lightgbm-4.6.0:\n",
      "      Successfully uninstalled lightgbm-4.6.0\n",
      "Successfully installed lightgbm-3.3.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\~ightgbm'.\n",
      "  You can safely remove it manually.\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "ERROR: Ignored the following yanked versions: 0.1.1\n",
      "ERROR: Could not find a version that satisfies the requirement catboost==0.26.1 (from versions: 1.2, 1.2.1, 1.2.2, 1.2.3, 1.2.5, 1.2.6, 1.2.7, 1.2.8)\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for catboost==0.26.1\n"
     ]
    }
   ],
   "source": [
    "%pip install lightgbm==3.3.2\n",
    "%pip install catboost==0.26.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d770157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# ðŸ“Œ Cell 1: Install & Imports\n",
    "# =============================\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "from sklearn.linear_model import Ridge, ElasticNet\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "590b239d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   system_id            timestamp  generation_W     load_W\n",
      "0         17  2023-08-14 01:50:00           0.0  525.66667\n",
      "1         17  2023-08-14 02:00:00           0.0  518.90000\n",
      "2         17  2023-08-14 02:10:00           0.0  528.50001\n",
      "3         17  2023-08-14 02:20:00           0.0  517.99999\n",
      "4         17  2023-08-14 02:30:00           0.0  520.90001\n",
      "    test_id  system_id            timestamp  generation_W      load_W\n",
      "0  QNN8B4SF         39  2023-08-12 17:40:00    2770.28574  3410.08823\n",
      "1  2XFLJU7J         39  2023-08-12 17:50:00    2198.08336  3183.79486\n",
      "2  ZTXR24I5         39  2023-08-12 18:00:00    1801.88889  2743.21568\n",
      "3  AE6LFBMV         39  2023-08-12 18:10:00    1419.09090  1630.29630\n",
      "4  RSDMSDW2         39  2023-08-12 18:20:00     897.99999  1788.60000\n",
      "   system_id connection_type     location  panels_capacity  load_capacity\n",
      "0          1     RESIDENTIAL    ISLAMABAD           11.125           10.0\n",
      "1          2      COMMERCIAL  SHEIKHUPURA            5.340            5.5\n",
      "2          3     RESIDENTIAL      KARACHI           10.350           10.0\n",
      "3          4     RESIDENTIAL       LAHORE           12.420           10.0\n",
      "4          5      COMMERCIAL      KARACHI           30.295           20.0\n"
     ]
    }
   ],
   "source": [
    "# =============================\n",
    "# ðŸ“Œ Cell 2: Load Data\n",
    "# =============================\n",
    "train = pd.read_csv(\"C:\\\\Users\\\\PC\\\\Desktop\\\\Bootcamp week 1 task\\\\BOOTCAMP-PROJECT\\\\giki-solar-energy-prediction-challenge\\\\train_data.csv\")\n",
    "test = pd.read_csv(\"C:\\\\Users\\\\PC\\\\Desktop\\\\Bootcamp week 1 task\\\\BOOTCAMP-PROJECT\\\\giki-solar-energy-prediction-challenge\\\\test_data_masked.csv\")\n",
    "systems = pd.read_csv(\"C:\\\\Users\\\\PC\\\\Desktop\\\\Bootcamp week 1 task\\\\BOOTCAMP-PROJECT\\\\giki-solar-energy-prediction-challenge\\\\systems_new.csv\")\n",
    "\n",
    "print(train.head())\n",
    "print(test.head())\n",
    "print(systems.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb9f49ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# ðŸ“Œ Cell 3: Merge Metadata\n",
    "# =============================\n",
    "train = train.merge(systems, on=\"system_id\", how=\"left\")\n",
    "test = test.merge(systems, on=\"system_id\", how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9d98ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# ðŸ“Œ Cell 4: Feature Engineering\n",
    "# =============================\n",
    "def create_features(df):\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "    df[\"hour\"] = df[\"timestamp\"].dt.hour\n",
    "    df[\"minute\"] = df[\"timestamp\"].dt.minute\n",
    "    df[\"dayofweek\"] = df[\"timestamp\"].dt.dayofweek\n",
    "    df[\"month\"] = df[\"timestamp\"].dt.month\n",
    "    \n",
    "    # Lags & Rolling\n",
    "    for col in [\"generation_W\", \"load_W\"]:\n",
    "        if col in df.columns:\n",
    "            for lag in [1, 2, 3, 6]:\n",
    "                df[f\"{col}_lag{lag}\"] = df.groupby(\"system_id\")[col].shift(lag)\n",
    "            df[f\"{col}_rolling3\"] = df.groupby(\"system_id\")[col].shift(1).rolling(3).mean()\n",
    "            df[f\"{col}_rolling6\"] = df.groupby(\"system_id\")[col].shift(1).rolling(6).mean()\n",
    "    \n",
    "    return df\n",
    "\n",
    "train = create_features(train)\n",
    "test = create_features(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8a9d352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# ðŸ“Œ Cell 5: Encode Categorical\n",
    "# =============================\n",
    "for col in [\"connection_type\", \"location\"]:\n",
    "    le = LabelEncoder()\n",
    "    full = pd.concat([train[col], test[col]], axis=0).astype(str)\n",
    "    le.fit(full)\n",
    "    train[col] = le.transform(train[col].astype(str))\n",
    "    test[col] = le.transform(test[col].astype(str))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "672e4f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using features: ['system_id', 'connection_type', 'location', 'panels_capacity', 'load_capacity', 'hour', 'minute', 'dayofweek', 'month', 'generation_W_lag1', 'generation_W_lag2', 'generation_W_lag3', 'generation_W_lag6', 'generation_W_rolling3', 'generation_W_rolling6', 'load_W_lag1', 'load_W_lag2', 'load_W_lag3', 'load_W_lag6', 'load_W_rolling3', 'load_W_rolling6']\n"
     ]
    }
   ],
   "source": [
    "# =============================\n",
    "# ðŸ“Œ Cell 6: Define Features & Targets\n",
    "# =============================\n",
    "target_cols = [\"generation_W\", \"load_W\"]\n",
    "drop_cols = [\"timestamp\"] + target_cols\n",
    "\n",
    "features = [col for col in train.columns if col not in drop_cols]\n",
    "print(\"Using features:\", features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59c7106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training models for generation_W\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 3244\n",
      "[LightGBM] [Info] Number of data points in the train set: 3079330, number of used features: 21\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 960, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 21 dense feature groups (70.48 MB) transferred to GPU in 0.107674 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 1810.037046\n"
     ]
    }
   ],
   "source": [
    "# =============================\n",
    "# ðŸ“Œ Cell 7: Train Base Models (Stacking, CUDA Compatible)\n",
    "# =============================\n",
    "oof_preds = {t: np.zeros(len(train)) for t in target_cols}\n",
    "test_preds = {t: np.zeros(len(test)) for t in target_cols}\n",
    "\n",
    "kf = GroupKFold(n_splits=5)\n",
    "\n",
    "for target in target_cols:\n",
    "    print(f\"\\nTraining models for {target}\")\n",
    "    X = train[features]\n",
    "    y = train[target]\n",
    "    groups = train[\"system_id\"]\n",
    "    Xt = test[features]\n",
    "    \n",
    "    oof = np.zeros(len(train))\n",
    "    fold_preds = np.zeros(len(test))\n",
    "    \n",
    "    for fold, (trn_idx, val_idx) in enumerate(kf.split(X, y, groups)):\n",
    "        X_tr, y_tr = X.iloc[trn_idx], y.iloc[trn_idx]\n",
    "        X_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n",
    "        \n",
    "        # âš¡ LightGBM (GPU)\n",
    "        lgb_model = lgb.LGBMRegressor(\n",
    "            n_estimators=500,\n",
    "            learning_rate=0.05,\n",
    "            device=\"gpu\"  # enable GPU\n",
    "        )\n",
    "        lgb_model.fit(\n",
    "            X_tr, y_tr,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            eval_metric=\"mae\"\n",
    "        )\n",
    "        lgb_val = lgb_model.predict(X_val)\n",
    "        lgb_test = lgb_model.predict(Xt)\n",
    "        \n",
    "        # âš¡ XGBoost (GPU)\n",
    "        xgb_model = xgb.XGBRegressor(\n",
    "            n_estimators=500,\n",
    "            learning_rate=0.05,\n",
    "            tree_method=\"gpu_hist\",  # use GPU\n",
    "            predictor=\"gpu_predictor\"\n",
    "        )\n",
    "        xgb_model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], verbose=False)\n",
    "        xgb_val = xgb_model.predict(X_val)\n",
    "        xgb_test = xgb_model.predict(Xt)\n",
    "        \n",
    "        # âš¡ CatBoost (GPU)\n",
    "        cb_model = cb.CatBoostRegressor(\n",
    "            iterations=500,\n",
    "            learning_rate=0.05,\n",
    "            task_type=\"GPU\",   # use GPU\n",
    "            devices=\"0\",       # first GPU\n",
    "            verbose=False\n",
    "        )\n",
    "        cb_model.fit(X_tr, y_tr, eval_set=(X_val, y_val), use_best_model=True)\n",
    "        cb_val = cb_model.predict(X_val)\n",
    "        cb_test = cb_model.predict(Xt)\n",
    "        \n",
    "        # ElasticNet (CPU only)\n",
    "        from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Imputer for ElasticNet (mean strategy for numerical features)\n",
    "        imputer = SimpleImputer(strategy=\"mean\")\n",
    "\n",
    "# Inside your training loop, replace ElasticNet section:\n",
    "# ------------------------------------------------------\n",
    "# Impute missing values\n",
    "        X_tr_enet = imputer.fit_transform(X_tr)\n",
    "        X_val_enet = imputer.transform(X_val)\n",
    "        Xt_enet = imputer.transform(Xt)\n",
    "\n",
    "# ElasticNet (CPU only)\n",
    "        enet = ElasticNet(alpha=0.1, l1_ratio=0.5, max_iter=10000)\n",
    "        enet.fit(X_tr_enet, y_tr)\n",
    "        enet_val = enet.predict(X_val_enet)\n",
    "        enet_test = enet.predict(Xt_enet)\n",
    "\n",
    "        \n",
    "        # Stack predictions\n",
    "        stack_val = np.vstack([lgb_val, xgb_val, cb_val, enet_val]).T\n",
    "        stack_test = np.vstack([lgb_test, xgb_test, cb_test, enet_test]).T\n",
    "        \n",
    "        # Meta model (Ridge, CPU)\n",
    "        meta = Ridge(alpha=1.0)\n",
    "        meta.fit(stack_val, y_val)\n",
    "        \n",
    "        oof[val_idx] = meta.predict(stack_val)\n",
    "        fold_preds += meta.predict(stack_test) / kf.n_splits\n",
    "    \n",
    "    oof_preds[target] = oof\n",
    "    test_preds[target] = fold_preds\n",
    "    \n",
    "    print(f\"{target} OOF MAE:\", mean_absolute_error(train[target], oof))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e5ebca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# ðŸ“Œ Cell 8: Create Submission\n",
    "# =============================\n",
    "submission = test[[\"system_id\", \"timestamp\"]].copy()\n",
    "submission[\"generation_W\"] = test_preds[\"generation_W\"]\n",
    "submission[\"load_W\"] = test_preds[\"load_W\"]\n",
    "\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(\"âœ… Submission file created!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
